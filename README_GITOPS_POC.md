# ðŸ“– CI/CD + GitOps POC - Complete Setup Guide

Welcome! This is a complete, ready-to-use CI/CD + GitOps proof-of-concept with Kubernetes, Argo CD, MySQL, and Apache Airflow 3.0.

## ðŸš€ START HERE (30 seconds)

### Option A: Fast Setup
```bash
make dev-up
```

### Option B: Interactive Setup
```bash
./QUICKSTART.sh
```

**Time**: ~5-10 minutes  
**Result**: Full local Kubernetes cluster with all services running

---

## ðŸ“š Documentation Index

Choose based on your needs:

| Document | Purpose | Read Time |
|----------|---------|-----------|
| **[SETUP.md](SETUP.md)** | ðŸ‘ˆ **START HERE** - Quick start & basic commands | 5 min |
| **[SETUP_SUMMARY.md](SETUP_SUMMARY.md)** | What was built & architecture overview | 5 min |
| **[GITOPS_POC_README.md](GITOPS_POC_README.md)** | Deep dive - config, troubleshooting, advanced topics | 15 min |
| **[Makefile](Makefile)** | All management targets & commands | See `make help` |

---

## ðŸŽ¯ Quick Command Reference

```bash
# Setup & teardown
make dev-up              # Start everything (run this first!)
make dev-down            # Stop and delete cluster

# Access services
make argocd-ui           # Open Argo CD dashboard
make airflow-ui          # Open Airflow dashboard

# Debugging
make status              # Show component health
make logs                # View recent logs
make validate            # Validate k8s manifests

# Help
make help                # Show all targets
```

---

## ðŸ—ï¸ What You'll Get

```
âœ… Kubernetes cluster (kind)
   â””â”€ 1 control-plane + 1 worker node

âœ… Argo CD (GitOps automation)
   â””â”€ Watches this repo for changes, auto-syncs

âœ… MySQL 8.0 (database)
   â””â”€ StatefulSet with persistent storage

âœ… Apache Airflow 3.0.1
   â”œâ”€ Webserver (UI)
   â”œâ”€ Scheduler (runs DAGs)
   â”œâ”€ Triggerer (required for Airflow 3.0)
   â””â”€ KubernetesExecutor (distributed task pods)
```

---

## ðŸ“‹ Setup Checklist

- [ ] Read this file (you're here! âœ“)
- [ ] Check [SETUP.md](SETUP.md) for prerequisites
- [ ] Run `make dev-up`
- [ ] Run `make status` to verify
- [ ] Open `make argocd-ui` and `make airflow-ui`
- [ ] Read [SETUP_SUMMARY.md](SETUP_SUMMARY.md) for architecture
- [ ] Bookmark [GITOPS_POC_README.md](GITOPS_POC_README.md) for reference

---

## âš¡ First 5 Minutes

```bash
# 1. Start everything
make dev-up

# 2. Check status
make status

# 3. Open Argo CD
make argocd-ui

# 4. Open Airflow
make airflow-ui

# 5. You're done!
```

---

## ðŸ”§ Credentials & Secrets

After `make dev-up`, credentials are saved locally:

```
.mysql-credentials.txt      â† MySQL passwords
.airflow-credentials.txt    â† Airflow secrets
```

**These are NOT committed to git** (protected by .gitignore)

To retrieve Argo CD admin password:
```bash
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath='{.data.password}' | base64 -d
```

---

## ðŸŒ Service URLs (after setup)

| Service | URL | How to Access |
|---------|-----|---------------|
| **Argo CD** | https://localhost:8080 | `make argocd-ui` |
| **Airflow** | http://localhost:8090 | `make airflow-ui` |
| **MySQL** | localhost:3306 | Internal only |

---

## ðŸ”„ GitOps Workflow

After setup, the GitOps workflow is automatic:

1. **Edit manifests** in `k8s/mysql/` or `k8s/airflow/`
2. **Commit & push** to GitHub
3. **Argo CD detects changes** within ~3 minutes
4. **Cluster auto-syncs** â†’ new resources deployed

Or manually sync:
```bash
argocd app sync mysql-app
argocd app sync airflow-app
```

---

## ðŸ“ Project Structure

```
.
â”œâ”€â”€ k8s/                              # Kubernetes manifests
â”‚   â”œâ”€â”€ mysql/
â”‚   â”‚   â”œâ”€â”€ base/                     # Base MySQL resources
â”‚   â”‚   â””â”€â”€ overlays/dev/             # Dev environment overlay
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ base/                     # Base Airflow resources
â”‚   â”‚   â””â”€â”€ overlays/dev/             # Dev environment overlay
â”‚   â””â”€â”€ apps/                         # Argo CD Applications
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ dev-up.sh                     # Bootstrap entire environment
â”‚   â”œâ”€â”€ dev-down.sh                   # Teardown
â”‚   â”œâ”€â”€ status.sh                     # Component status
â”‚   â”œâ”€â”€ argocd-port-forward.sh        # Argo CD UI access
â”‚   â””â”€â”€ airflow-port-forward.sh       # Airflow UI access
â”‚
â”œâ”€â”€ Makefile                          # Management targets
â”œâ”€â”€ SETUP.md                          # Quick start guide
â”œâ”€â”€ SETUP_SUMMARY.md                  # What was built
â”œâ”€â”€ GITOPS_POC_README.md              # Full reference
â””â”€â”€ README.md                         # This file
```

---

## ðŸ§ª Test It Out

### Create a Simple DAG

```bash
# Create dags directory
mkdir -p dags

# Create a simple DAG
cat > dags/hello_dag.py << 'EOF'
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG('hello_dag', start_date=datetime(2024, 1, 1)):
    BashOperator(task_id='hello', bash_command='echo Hello Airflow!')
EOF

# Commit & push
git add dags/hello_dag.py
git commit -m "Add hello DAG"
git push

# Wait ~3 min for sync, then check Airflow UI
make airflow-ui
```

---

## ðŸ› Troubleshooting

**Services not ready?**
```bash
make status          # Check component health
make logs            # View recent logs
```

**Cluster already exists?**
```bash
make dev-down
make dev-up
```

**Tools not installed?**
```bash
make install-prereqs
```

**Full troubleshooting guide**: See [GITOPS_POC_README.md](GITOPS_POC_README.md)

---

## ðŸ“š Learning Resources

- ðŸ“– [Argo CD Docs](https://argo-cd.readthedocs.io/)
- ðŸ“– [Airflow 3.0 Docs](https://airflow.apache.org/docs/apache-airflow/stable/)
- ðŸ“– [Kubernetes Docs](https://kubernetes.io/docs/)
- ðŸ“– [Kustomize Docs](https://kustomize.io/)
- ðŸ“– [kind Docs](https://kind.sigs.k8s.io/)

---

## ðŸ’¾ Cleanup

To completely remove everything:

```bash
make dev-down
```

This will:
- Delete the kind cluster
- Remove all running services
- Clean up credential files
- Free up disk space

---

## ðŸŽ“ Next Steps

### Immediate
1. âœ… Run `make dev-up`
2. âœ… Check `make status`
3. âœ… Explore Argo CD UI
4. âœ… Explore Airflow UI

### Next
1. Read [SETUP_SUMMARY.md](SETUP_SUMMARY.md) for architecture details
2. Modify a manifest and watch GitOps auto-sync
3. Deploy a test DAG
4. Review Airflow logs

### Advanced
1. Read [GITOPS_POC_README.md](GITOPS_POC_README.md) for all features
2. Add custom Python packages to Airflow image
3. Scale components (scheduler, webserver)
4. Deploy to a real Kubernetes cluster (update REPO_URL)

---

## â“ FAQ

**Q: How long does setup take?**  
A: ~5-10 minutes depending on internet speed and system resources.

**Q: Can I use this in production?**  
A: This is a POC/demo setup. For production, see recommendations in [GITOPS_POC_README.md](GITOPS_POC_README.md).

**Q: What if I modify the cluster manually?**  
A: Argo CD will reconcile it back to the desired state from git. That's GitOps!

**Q: How do I add more DAGs?**  
A: Add `.py` files to `dags/` folder, commit & push. Airflow auto-discovers them.

**Q: Can I scale components?**  
A: Yes! Edit `k8s/airflow/overlays/dev/kustomization.yaml` and adjust replicas.

---

## ðŸ†˜ Getting Help

1. Check [SETUP.md](SETUP.md) for quick commands
2. Review [GITOPS_POC_README.md](GITOPS_POC_README.md) troubleshooting section
3. Run `make status` and `make logs`
4. Check Kubernetes events: `kubectl get events -A`

---

## ðŸ“ Summary

You now have a **complete, production-inspired CI/CD + GitOps POC** with:

âœ… **Infrastructure as Code**: All resources defined in git  
âœ… **Automatic Sync**: Argo CD keeps cluster in sync with repo  
âœ… **Distributed DAGs**: Airflow KubernetesExecutor runs tasks as pods  
âœ… **Persistent Storage**: MySQL with PVC for data durability  
âœ… **Security**: RBAC, secrets, health checks, logging  
âœ… **Documentation**: Complete setup, troubleshooting, references  

---

## ðŸŽ‰ Ready to Start?

```bash
make dev-up
```

**Questions?** See [SETUP.md](SETUP.md) or [GITOPS_POC_README.md](GITOPS_POC_README.md)

---

**Last Updated**: February 25, 2026  
**Status**: âœ… Complete and ready to use
